{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235be5f1",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae43136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff330ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOOFED_DIR_TEST = \"fake\"\n",
    "AUTHENTIC_DIR_TRAIN = \"real\"\n",
    "\n",
    "SCALER_FILE = \"anomaly_scaler.joblib\"\n",
    "MODEL_FILE = \"voice_anomaly_detector.joblib\"\n",
    "TRAIN_STATS_FILE = \"train_feature_stats.joblib\"\n",
    "\n",
    "SR, N_FFT, N_MFCC, HOP_LENGTH = 16000, 2048, 20, 512\n",
    "FEATURE_NAMES = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8efbea",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70bc1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path, sr=SR, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    global FEATURE_NAMES\n",
    "\n",
    "    signal, sr_loaded = librosa.load(audio_path, sr=sr, mono=True)\n",
    "    if sr_loaded != sr:\n",
    "        print(f\"Warning: Audio at {audio_path} has sample rate {sr_loaded}, resampling to {sr}.\")\n",
    "\n",
    "    if len(signal) < n_fft:\n",
    "        signal = np.pad(signal, (0, n_fft - len(signal)), 'constant')\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    mfccs_std = np.std(mfccs.T, axis=0)\n",
    "\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=signal, frame_length=n_fft, hop_length=hop_length)\n",
    "    zcr_mean = np.mean(zcr)\n",
    "    zcr_std = np.std(zcr)\n",
    "\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=signal, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "    spectral_centroid_mean = np.mean(spectral_centroid)\n",
    "    spectral_centroid_std = np.std(spectral_centroid)\n",
    "\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=signal, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "    spectral_rolloff_mean = np.mean(spectral_rolloff)\n",
    "    spectral_rolloff_std = np.std(spectral_rolloff)\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=signal, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "    chroma_mean = np.mean(chroma.T, axis=0)\n",
    "    chroma_std = np.std(chroma.T, axis=0)\n",
    "\n",
    "    f0, _, _ = librosa.pyin(signal, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'), sr=sr, frame_length=n_fft, hop_length=hop_length)\n",
    "    f0_mean = np.nanmean(f0)\n",
    "    f0_std = np.nanstd(f0)\n",
    "    f0_mean = 0 if np.isnan(f0_mean) else f0_mean\n",
    "    f0_std = 0 if np.isnan(f0_std) else f0_std\n",
    "\n",
    "    features = np.hstack([\n",
    "        mfccs_mean, mfccs_std,\n",
    "        zcr_mean, zcr_std,\n",
    "        spectral_centroid_mean, spectral_centroid_std,\n",
    "        spectral_rolloff_mean, spectral_rolloff_std,\n",
    "        f0_mean, f0_std\n",
    "    ])\n",
    "    features = np.concatenate([features, chroma_mean, chroma_std])\n",
    "\n",
    "    if not FEATURE_NAMES:\n",
    "        for i in range(n_mfcc): FEATURE_NAMES.append(f\"mfcc_mean_{i+1}\")\n",
    "        for i in range(n_mfcc): FEATURE_NAMES.append(f\"mfcc_std_{i+1}\")\n",
    "\n",
    "        FEATURE_NAMES.extend([\"zcr_mean\", \"zcr_std\",\n",
    "                                \"spectral_centroid_mean\", \"spectral_centroid_std\",\n",
    "                                \"spectral_rolloff_mean\", \"spectral_rolloff_std\",\n",
    "                                \"f0_mean\", \"f0_std\"])\n",
    "\n",
    "        for i in range(chroma_mean.shape[0]): FEATURE_NAMES.append(f\"chroma_mean_{i+1}\")\n",
    "        for i in range(chroma_std.shape[0]): FEATURE_NAMES.append(f\"chroma_std_{i+1}\")\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8276c073",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5cdca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_authentic_training_data(authentic_dir):\n",
    "    features_list = []\n",
    "\n",
    "    print(f\"Loading authentic training samples from: {authentic_dir}\")\n",
    "    if not os.path.exists(authentic_dir):\n",
    "        print(f\"ERROR: Authentic training directory '{authentic_dir}' not found.\")\n",
    "        return np.array([])\n",
    "\n",
    "    for filename in os.listdir(authentic_dir):\n",
    "        if filename.lower().endswith(('.wav', '.mp3')):\n",
    "            path = os.path.join(authentic_dir, filename)\n",
    "            feats = extract_features(path)\n",
    "\n",
    "            if not np.isnan(feats).any():\n",
    "                features_list.append(feats)\n",
    "            else:\n",
    "                print(f\"Skipping {filename} due to feature extraction errors.\")\n",
    "                \n",
    "    return np.array(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e2860",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14190c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_anomaly_model(X_train_authentic):\n",
    "    if X_train_authentic.shape[0] == 0:\n",
    "        print(\"No authentic training data to train on. Exiting training.\")\n",
    "        return None, None, None\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_authentic)\n",
    "\n",
    "    train_means = np.mean(X_train_scaled, axis=0)\n",
    "    train_stds = np.std(X_train_scaled, axis=0)\n",
    "    joblib.dump({'means': train_means, 'stds': train_stds}, TRAIN_STATS_FILE)\n",
    "\n",
    "    model = OneClassSVM(nu=0.05, kernel=\"rbf\", gamma='scale')\n",
    "    model.fit(X_train_scaled)\n",
    "\n",
    "    joblib.dump(model, MODEL_FILE)\n",
    "    joblib.dump(scaler, SCALER_FILE)\n",
    "    \n",
    "    print(f\"\\nAnomaly detection model saved to {MODEL_FILE}\")\n",
    "    print(f\"Scaler saved to {SCALER_FILE}\")\n",
    "    print(f\"Training feature stats saved to {TRAIN_STATS_FILE}\")\n",
    "    \n",
    "    return model, scaler, {'means': train_means, 'stds': train_stds}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2a086",
   "metadata": {},
   "source": [
    "# Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40170ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomaly_and_explain(audio_path, model, scaler, train_feature_stats, feature_names, anom_threshold_std=2.5):\n",
    "\n",
    "    print(f\"\\n--- Analyzing: {audio_path} ---\")\n",
    "    new_features = extract_features(audio_path)\n",
    "    if np.isnan(new_features).any():\n",
    "        print(\"Could not extract valid features from the audio file.\")\n",
    "        return\n",
    "\n",
    "    new_features_scaled = scaler.transform(new_features.reshape(1, -1))\n",
    "    prediction = model.predict(new_features_scaled)[0]\n",
    "    anomaly_score = model.decision_function(new_features_scaled)[0]\n",
    "\n",
    "    if anomaly_score >= -0.025:\n",
    "        label = \"Likely Authentic (Normal)\"\n",
    "        print(f\"Prediction: {label}\")\n",
    "\n",
    "    else:\n",
    "        label = \"Potentially Spoofed (Anomaly)\"\n",
    "        print(f\"Prediction: {label}\")\n",
    "        print(\"\\nFeatures contributing to anomaly detection (deviation from authentic training data):\")\n",
    "\n",
    "        deviations = []\n",
    "        train_means = train_feature_stats['means']\n",
    "        train_stds = train_feature_stats['stds']\n",
    "\n",
    "        for i in range(len(feature_names)):\n",
    "            std_dev = train_stds[i] if train_stds[i] > 1e-6 else 1.0\n",
    "            deviation_in_stds = (new_features_scaled[0, i] - train_means[i]) / std_dev\n",
    "            \n",
    "            if abs(deviation_in_stds) > anom_threshold_std :\n",
    "                deviations.append({\n",
    "                    \"feature\": feature_names[i],\n",
    "                    \"value\": new_features[i],\n",
    "                    \"scaled_value\": new_features_scaled[0, i],\n",
    "                    \"train_mean_scaled\": train_means[i],\n",
    "                    \"train_std_scaled\": train_stds[i],\n",
    "                    \"deviation_stds\": deviation_in_stds\n",
    "                })\n",
    "                \n",
    "        deviations.sort(key=lambda x: abs(x[\"deviation_stds\"]), reverse=True)\n",
    "        if not deviations and prediction == -1:\n",
    "            print(\"  Anomaly detected, but individual feature deviations are not above threshold. Overall pattern is anomalous.\")\n",
    "        elif not deviations and prediction == 1:\n",
    "            print(\"  All features within typical authentic ranges.\")\n",
    "\n",
    "\n",
    "        for dev_info in deviations[:10]:\n",
    "            direction = \"higher\" if dev_info[\"deviation_stds\"] > 0 else \"lower\"\n",
    "            print(f\"  - {dev_info['feature']}: {dev_info['value']:.2f} \"\n",
    "                f\"(Scaled: {dev_info['scaled_value']:.2f}, \"\n",
    "                f\"Train Mean Scaled: {dev_info['train_mean_scaled']:.2f}). \"\n",
    "                f\"This is {abs(dev_info['deviation_stds']):.2f} std devs {direction} than typical authentic samples.\")\n",
    "        \n",
    "        if prediction == -1 and not deviations:\n",
    "            print(\"  The combination of features makes this sample an outlier, even if individual features aren't extremely deviant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e80bd",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "194fb161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading authentic training samples from: real\n",
      "\n",
      "Anomaly detection model saved to voice_anomaly_detector.joblib\n",
      "Scaler saved to anomaly_scaler.joblib\n",
      "Training feature stats saved to train_feature_stats.joblib\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "scaler = None\n",
    "train_feature_stats = None\n",
    "\n",
    "X_authentic_train = load_authentic_training_data(AUTHENTIC_DIR_TRAIN)\n",
    "model, scaler, train_feature_stats = train_anomaly_model(X_authentic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07008b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing: real\\DonaldTrump.mp3 ---\n",
      "Prediction: Likely Authentic (Normal)\n",
      "\n",
      "--- Analyzing: real\\Elon Musk Works 120 Hours Every Week.mp3 ---\n",
      "Prediction: Likely Authentic (Normal)\n",
      "\n",
      "--- Analyzing: real\\ModiVoice.mp3 ---\n",
      "Prediction: Likely Authentic (Normal)\n",
      "\n",
      "--- Analyzing: real\\MorganFreeman.mp3 ---\n",
      "Prediction: Likely Authentic (Normal)\n",
      "\n",
      "--- Analyzing: real\\MrBeast.mp3 ---\n",
      "Prediction: Likely Authentic (Normal)\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(AUTHENTIC_DIR_TRAIN):\n",
    "    detect_anomaly_and_explain(os.path.join(AUTHENTIC_DIR_TRAIN, file), model, scaler, train_feature_stats, FEATURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "161a1894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing: fake\\DonaldTrump1.mp3 ---\n",
      "Prediction: Potentially Spoofed (Anomaly)\n",
      "\n",
      "Features contributing to anomaly detection (deviation from authentic training data):\n",
      "  - chroma_std_10: 0.35 (Scaled: 4.94, Train Mean Scaled: 0.00). This is 4.94 std devs higher than typical authentic samples.\n",
      "  - chroma_std_11: 0.36 (Scaled: 2.79, Train Mean Scaled: -0.00). This is 2.79 std devs higher than typical authentic samples.\n",
      "  - mfcc_std_9: 16.70 (Scaled: 2.68, Train Mean Scaled: 0.00). This is 2.68 std devs higher than typical authentic samples.\n",
      "  - chroma_std_7: 0.33 (Scaled: 2.67, Train Mean Scaled: 0.00). This is 2.67 std devs higher than typical authentic samples.\n",
      "\n",
      "--- Analyzing: fake\\DonaldTrump2.wav ---\n",
      "Prediction: Potentially Spoofed (Anomaly)\n",
      "\n",
      "Features contributing to anomaly detection (deviation from authentic training data):\n",
      "  - mfcc_std_4: 49.75 (Scaled: 6.65, Train Mean Scaled: 0.00). This is 6.65 std devs higher than typical authentic samples.\n",
      "  - mfcc_std_2: 87.65 (Scaled: 6.62, Train Mean Scaled: 0.00). This is 6.62 std devs higher than typical authentic samples.\n",
      "  - mfcc_std_6: 27.77 (Scaled: 3.98, Train Mean Scaled: 0.00). This is 3.98 std devs higher than typical authentic samples.\n",
      "  - spectral_rolloff_mean: 2231.84 (Scaled: -3.62, Train Mean Scaled: 0.00). This is 3.62 std devs lower than typical authentic samples.\n",
      "  - mfcc_std_9: 18.32 (Scaled: 3.56, Train Mean Scaled: 0.00). This is 3.56 std devs higher than typical authentic samples.\n",
      "  - spectral_centroid_std: 1150.45 (Scaled: 3.36, Train Mean Scaled: 0.00). This is 3.36 std devs higher than typical authentic samples.\n",
      "  - chroma_std_2: 0.33 (Scaled: 3.16, Train Mean Scaled: -0.00). This is 3.16 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_9: 0.28 (Scaled: -3.12, Train Mean Scaled: -0.00). This is 3.12 std devs lower than typical authentic samples.\n",
      "  - chroma_std_7: 0.33 (Scaled: 2.92, Train Mean Scaled: 0.00). This is 2.92 std devs higher than typical authentic samples.\n",
      "  - mfcc_std_10: 16.64 (Scaled: 2.80, Train Mean Scaled: 0.00). This is 2.80 std devs higher than typical authentic samples.\n",
      "\n",
      "--- Analyzing: fake\\ElonMusk1.mp3 ---\n",
      "Prediction: Potentially Spoofed (Anomaly)\n",
      "\n",
      "Features contributing to anomaly detection (deviation from authentic training data):\n",
      "  - mfcc_mean_16: 1.85 (Scaled: 3.13, Train Mean Scaled: -0.00). This is 3.13 std devs higher than typical authentic samples.\n",
      "  - mfcc_std_11: 14.39 (Scaled: 2.78, Train Mean Scaled: -0.00). This is 2.78 std devs higher than typical authentic samples.\n",
      "  - mfcc_mean_7: 2.52 (Scaled: 2.68, Train Mean Scaled: 0.00). This is 2.68 std devs higher than typical authentic samples.\n",
      "\n",
      "--- Analyzing: fake\\ElonMusk2.mp3 ---\n",
      "Prediction: Potentially Spoofed (Anomaly)\n",
      "\n",
      "Features contributing to anomaly detection (deviation from authentic training data):\n",
      "  - chroma_std_10: 0.28 (Scaled: -3.82, Train Mean Scaled: 0.00). This is 3.82 std devs lower than typical authentic samples.\n",
      "  - chroma_mean_2: 0.39 (Scaled: 3.61, Train Mean Scaled: -0.00). This is 3.61 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_7: 0.51 (Scaled: 3.14, Train Mean Scaled: -0.00). This is 3.14 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_5: 0.47 (Scaled: 2.90, Train Mean Scaled: -0.00). This is 2.90 std devs higher than typical authentic samples.\n",
      "  - mfcc_std_2: 62.10 (Scaled: 2.86, Train Mean Scaled: 0.00). This is 2.86 std devs higher than typical authentic samples.\n",
      "  - mfcc_mean_11: 1.60 (Scaled: 2.53, Train Mean Scaled: -0.00). This is 2.53 std devs higher than typical authentic samples.\n",
      "  - mfcc_mean_16: 0.69 (Scaled: 2.52, Train Mean Scaled: -0.00). This is 2.52 std devs higher than typical authentic samples.\n",
      "\n",
      "--- Analyzing: fake\\Modi1.mp3 ---\n",
      "Prediction: Potentially Spoofed (Anomaly)\n",
      "\n",
      "Features contributing to anomaly detection (deviation from authentic training data):\n",
      "  - chroma_mean_2: 0.40 (Scaled: 3.93, Train Mean Scaled: -0.00). This is 3.93 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_5: 0.49 (Scaled: 3.51, Train Mean Scaled: -0.00). This is 3.51 std devs higher than typical authentic samples.\n",
      "  - chroma_std_10: 0.28 (Scaled: -3.42, Train Mean Scaled: 0.00). This is 3.42 std devs lower than typical authentic samples.\n",
      "  - chroma_std_6: 0.27 (Scaled: -3.22, Train Mean Scaled: -0.00). This is 3.22 std devs lower than typical authentic samples.\n",
      "  - chroma_std_7: 0.24 (Scaled: -2.80, Train Mean Scaled: 0.00). This is 2.80 std devs lower than typical authentic samples.\n",
      "  - mfcc_mean_6: -27.25 (Scaled: -2.76, Train Mean Scaled: -0.00). This is 2.76 std devs lower than typical authentic samples.\n",
      "\n",
      "--- Analyzing: fake\\Modi2.wav ---\n",
      "Prediction: Potentially Spoofed (Anomaly)\n",
      "\n",
      "Features contributing to anomaly detection (deviation from authentic training data):\n",
      "  - spectral_rolloff_mean: 2129.27 (Scaled: -4.14, Train Mean Scaled: 0.00). This is 4.14 std devs lower than typical authentic samples.\n",
      "  - spectral_centroid_mean: 1125.04 (Scaled: -3.32, Train Mean Scaled: 0.00). This is 3.32 std devs lower than typical authentic samples.\n",
      "  - chroma_std_10: 0.33 (Scaled: 3.21, Train Mean Scaled: 0.00). This is 3.21 std devs higher than typical authentic samples.\n",
      "  - mfcc_mean_14: 6.61 (Scaled: 2.92, Train Mean Scaled: 0.00). This is 2.92 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_10: 0.52 (Scaled: 2.88, Train Mean Scaled: -0.00). This is 2.88 std devs higher than typical authentic samples.\n",
      "  - mfcc_mean_2: 132.29 (Scaled: 2.81, Train Mean Scaled: -0.00). This is 2.81 std devs higher than typical authentic samples.\n",
      "  - chroma_std_7: 0.33 (Scaled: 2.60, Train Mean Scaled: 0.00). This is 2.60 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_2: 0.23 (Scaled: -2.53, Train Mean Scaled: -0.00). This is 2.53 std devs lower than typical authentic samples.\n",
      "\n",
      "--- Analyzing: fake\\MorganFreeMan1.mp3 ---\n",
      "Prediction: Potentially Spoofed (Anomaly)\n",
      "\n",
      "Features contributing to anomaly detection (deviation from authentic training data):\n",
      "  - chroma_std_10: 0.37 (Scaled: 7.61, Train Mean Scaled: 0.00). This is 7.61 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_10: 0.63 (Scaled: 4.89, Train Mean Scaled: -0.00). This is 4.89 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_9: 0.48 (Scaled: 2.65, Train Mean Scaled: -0.00). This is 2.65 std devs higher than typical authentic samples.\n",
      "  - spectral_centroid_mean: 1238.33 (Scaled: -2.51, Train Mean Scaled: 0.00). This is 2.51 std devs lower than typical authentic samples.\n",
      "\n",
      "--- Analyzing: fake\\MorganFreeman2.wav ---\n",
      "Prediction: Potentially Spoofed (Anomaly)\n",
      "\n",
      "Features contributing to anomaly detection (deviation from authentic training data):\n",
      "  - mfcc_std_2: 70.30 (Scaled: 4.07, Train Mean Scaled: 0.00). This is 4.07 std devs higher than typical authentic samples.\n",
      "  - spectral_centroid_std: 1160.63 (Scaled: 3.44, Train Mean Scaled: 0.00). This is 3.44 std devs higher than typical authentic samples.\n",
      "  - zcr_std: 0.13 (Scaled: 3.09, Train Mean Scaled: 0.00). This is 3.09 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_7: 0.50 (Scaled: 3.08, Train Mean Scaled: -0.00). This is 3.08 std devs higher than typical authentic samples.\n",
      "  - chroma_std_7: 0.33 (Scaled: 2.90, Train Mean Scaled: 0.00). This is 2.90 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_2: 0.37 (Scaled: 2.67, Train Mean Scaled: -0.00). This is 2.67 std devs higher than typical authentic samples.\n",
      "\n",
      "--- Analyzing: fake\\MrBeast1.mp3 ---\n",
      "Prediction: Potentially Spoofed (Anomaly)\n",
      "\n",
      "Features contributing to anomaly detection (deviation from authentic training data):\n",
      "  - chroma_std_10: 0.33 (Scaled: 2.87, Train Mean Scaled: 0.00). This is 2.87 std devs higher than typical authentic samples.\n",
      "  - chroma_std_2: 0.32 (Scaled: 2.53, Train Mean Scaled: -0.00). This is 2.53 std devs higher than typical authentic samples.\n",
      "\n",
      "--- Analyzing: fake\\MrBeast2.wav ---\n",
      "Prediction: Potentially Spoofed (Anomaly)\n",
      "\n",
      "Features contributing to anomaly detection (deviation from authentic training data):\n",
      "  - mfcc_std_4: 51.33 (Scaled: 7.10, Train Mean Scaled: 0.00). This is 7.10 std devs higher than typical authentic samples.\n",
      "  - chroma_std_10: 0.35 (Scaled: 5.43, Train Mean Scaled: 0.00). This is 5.43 std devs higher than typical authentic samples.\n",
      "  - mfcc_mean_16: -13.20 (Scaled: -4.80, Train Mean Scaled: -0.00). This is 4.80 std devs lower than typical authentic samples.\n",
      "  - mfcc_mean_4: 90.38 (Scaled: 3.77, Train Mean Scaled: -0.00). This is 3.77 std devs higher than typical authentic samples.\n",
      "  - chroma_std_8: 0.25 (Scaled: -3.53, Train Mean Scaled: -0.00). This is 3.53 std devs lower than typical authentic samples.\n",
      "  - mfcc_mean_14: -11.23 (Scaled: -3.52, Train Mean Scaled: 0.00). This is 3.52 std devs lower than typical authentic samples.\n",
      "  - chroma_std_2: 0.33 (Scaled: 3.39, Train Mean Scaled: -0.00). This is 3.39 std devs higher than typical authentic samples.\n",
      "  - mfcc_std_8: 21.13 (Scaled: 3.32, Train Mean Scaled: -0.00). This is 3.32 std devs higher than typical authentic samples.\n",
      "  - chroma_mean_4: 0.23 (Scaled: -3.07, Train Mean Scaled: -0.00). This is 3.07 std devs lower than typical authentic samples.\n",
      "  - chroma_mean_10: 0.53 (Scaled: 3.05, Train Mean Scaled: -0.00). This is 3.05 std devs higher than typical authentic samples.\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(SPOOFED_DIR_TEST):\n",
    "    detect_anomaly_and_explain(os.path.join(SPOOFED_DIR_TEST, file), model, scaler, train_feature_stats, FEATURE_NAMES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
